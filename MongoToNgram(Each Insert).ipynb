{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import _uniout\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def no_court(content):\n",
    "    try:\n",
    "        court_no = {u\"臺北地方\":100,u\"士林地方\":111,u\"新北地方\":220,u\"宜蘭地方\":260,u\"基隆地方\":200,u\"桃園地方\":320,u\"新竹地方\":300,u\"苗栗地方\":350,u\"臺中地方\":400,u\"彰化地方\":500,u\"南投地方\":540,u\"臺南地方\":700,u\"高雄地方\":800,u\"花蓮地方\":970,u\"雲林地方\":630,u\"嘉義地方\":602,u\"臺東地方\":950,u\"屏東地方\":900,u\"澎湖地方\":880,u\"金門地方\":890,u\"連江地方\":209,u\"高雄少年及家事\":850}\n",
    "        m = re.search(u'[  \\d]*(灣|福建|臺灣)(\\S{4,7})法院(民事|家事|暫時|支付)(\\S{2})',content)\n",
    "        return str(court_no[m.group(2)])\n",
    "    except:\n",
    "        print \"Rex Err:\"+m.group(2)\n",
    "def no_jurytype(content):\n",
    "    try:\n",
    "        jurytype_no = {u\"婚\":11,u\"婚再\":12,u\"婚更\":13,u\"家聲\":21,u\"家訴\":22,u\"家抗\":23,u\"家陸許\":24,u\"司家聲\":30,u\"基家簡\":25,u\"重家訴\":26,u\"婚更一\":27,u\"婚更(一)\":28,u\"司家調\":29,u\"家移調\":31,u\"家簡\":32,u\"家調裁\":33,u\"家查\":34,u\"家聲抗\":35,u\"家調裁\":36,u\"家調補\":37,u\"司家補\":38,u\"家親聲\":39,u\"司家簡調\":40,u\"家簡上\":41,u\"家小\":42,u\"家救\":43,u\"家小上\":44,u\"家婚聲\":45,u\"家再\":46,u\"家他\":47,u\"訴\":48,u\"重訴\":49,u\"家續\":50,u\"審訴\":51,u\"聲\":52,u\"補\":90}\n",
    "        m = re.search(u'(【裁判字號】)(.*?),(.*?),(\\d{1,4})[^【】 ]',content)\n",
    "        return m.group(2)+\"_\"+str(jurytype_no[m.group(3)])+\"_\"+m.group(4)\n",
    "    except:\n",
    "        print \"Rex Err:\"+m.group(2)\n",
    "def judgedate(content):\n",
    "    m = re.search(u'(【裁判日期】)(\\d{6,7})',content)\n",
    "    return m.group(2)\n",
    "\n",
    "def getPK(content):\n",
    "    return no_court(content)+\"_\"+no_jurytype(content)+\"_\"+judgedate(content)\n",
    "\n",
    "#make a connection to mongodb \n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "#assign db_name to db\n",
    "db = client.test\n",
    "#make the collection in the db of test\n",
    "samples = db['samples']\n",
    "#print the case number in db.dday\n",
    "for dic in db.samples.find({\"_id\":\"100_88_11_226_890623\"}):\n",
    "    #print _uniout.unescape(str(i),'utf-8') \n",
    "    content = dic['content'] #append all the jurybook to the content\n",
    "    pk = getPK(content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-*- utf-8 -*-\n",
    "import codecs\n",
    "import operator\n",
    "import os\n",
    "import re\n",
    "import _uniout\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def no_court(content):\n",
    "    try:\n",
    "        court_no = {u\"臺北地方\":100,u\"士林地方\":111,u\"新北地方\":220,u\"宜蘭地方\":260,u\"基隆地方\":200,u\"桃園地方\":320,u\"新竹地方\":300,u\"苗栗地方\":350,u\"臺中地方\":400,u\"彰化地方\":500,u\"南投地方\":540,u\"臺南地方\":700,u\"高雄地方\":800,u\"花蓮地方\":970,u\"雲林地方\":630,u\"嘉義地方\":602,u\"臺東地方\":950,u\"屏東地方\":900,u\"澎湖地方\":880,u\"金門地方\":890,u\"連江地方\":209,u\"高雄少年及家事\":850}\n",
    "        m = re.search(u'[  \\d]*(灣|福建|臺灣)(\\S{4,7})法院(民事|家事|暫時|支付)(\\S{2})',content)\n",
    "        return str(court_no[m.group(2)])\n",
    "    except:\n",
    "        print \"Rex Err:\"+m.group(2)\n",
    "def no_jurytype(content):\n",
    "    try:\n",
    "        jurytype_no = {u\"婚\":11,u\"婚再\":12,u\"婚更\":13,u\"家聲\":21,u\"家訴\":22,u\"家抗\":23,u\"家陸許\":24,u\"司家聲\":30,u\"基家簡\":25,u\"重家訴\":26,u\"婚更一\":27,u\"婚更(一)\":28,u\"司家調\":29,u\"家移調\":31,u\"家簡\":32,u\"家調裁\":33,u\"家查\":34,u\"家聲抗\":35,u\"家調裁\":36,u\"家調補\":37,u\"司家補\":38,u\"家親聲\":39,u\"司家簡調\":40,u\"家簡上\":41,u\"家小\":42,u\"家救\":43,u\"家小上\":44,u\"家婚聲\":45,u\"家再\":46,u\"家他\":47,u\"訴\":48,u\"重訴\":49,u\"家續\":50,u\"審訴\":51,u\"聲\":52,u\"補\":90}\n",
    "        m = re.search(u'(【裁判字號】)(.*?),(.*?),(\\d{1,4})[^【】 ]',content)\n",
    "        return m.group(2)+\"_\"+str(jurytype_no[m.group(3)])+\"_\"+m.group(4)\n",
    "    except:\n",
    "        print \"Rex Err:\"+m.group(2)\n",
    "def judgedate(content):\n",
    "    m = re.search(u'(【裁判日期】)(\\d{6,7})',content)\n",
    "    return m.group(2)\n",
    "\n",
    "def getPK(content):\n",
    "    return no_court(content)+\"_\"+no_jurytype(content)+\"_\"+judgedate(content)\n",
    "\n",
    "cutlist = \" <>/:：;；,、＂’，.。！？｢\\\"\\'\\\\\\n\\r《》“”!@#$%^&*()\".decode(\"utf-8\")  ##列出標點符號，並轉換成utf-8的格式\n",
    "def cutSentence(content, stopwords): ##放入原始文章路徑, 增加斷詞的list\n",
    "    sentence = \"\"\n",
    "    textList = []\n",
    "       \n",
    "    for line in content:\n",
    "        line = line.strip() ##清除空白\n",
    "        #line = line.replace(' ', '')\n",
    "        for word in line:\n",
    "            if word not in cutlist: #如果文字不是標點符號，就把字加到句子中\n",
    "                sentence += word\n",
    "                #print sentence\n",
    "            else:\n",
    "                #stopwords =[u'裁判']\n",
    "                for stopword in stopwords:  #清除關鍵字\n",
    "                    #print stopword\n",
    "                    sentence = sentence.replace(stopword,'')\n",
    "                    #print type(stopword)\n",
    "                #print sentence\n",
    "                textList.append(sentence) #把文章句子依標點符號與空白隔開\n",
    "                sentence = \"\"\n",
    "            #for ele in textList: #顯示文章所斷句子\n",
    "                #print ele\n",
    "    return textList\n",
    "    \n",
    "def ngram(textLists,n): \n",
    "    #首參數放處理好的文章(LIST檔，utf-8編碼)次參數放字詞的長度單位，第三個參數放多少頻次以上\n",
    "    words=[]     #存放擷取出來的字詞\n",
    "    words_freq={}#存放字詞:計算個數 \n",
    "    result= []\n",
    "    for textList in textLists:\n",
    "        for w in range(len(textList)-(n-1)): #要讀取的長度隨字詞長度改變\n",
    "            words.append(textList[w:w+n])    #抓取長度w-(n-1)的字串\n",
    "\n",
    "    for word in words:\n",
    "        if word not in words_freq:               #如果這個字詞還沒有被放在字典檔中\n",
    "            words_freq[word] = words.count(word) #就開一個新的字詞，裡面放入字詞計算的頻次\n",
    " \n",
    "    #words_freq = sorted(words_freq.iteritems(),key=operator.itemgetter(1),reverse=True) #change words_freq from dict to list \n",
    "    \n",
    "    #for word in words_freq:\n",
    "        #if word[1] >= minFreq:\n",
    "            #result.append(word)\n",
    "    return words_freq ##回傳一個陣列[(詞,頻次),(詞,頻次)]\n",
    "\n",
    "def longTermPriority(path, maxTermLength, minFreq):   #目前設定只傳回長詞longTerms\n",
    "    stopwords=[]\n",
    "    words_freq = {}\n",
    "    brokenwords = {}\n",
    "    with codecs.open('./ngram/stopwords.txt','r' ,'utf-8') as f :\n",
    "        readstopwords = f.readlines() #從txt檔讀取每行的停止詞\n",
    "    for ele in readstopwords:\n",
    "        stopwords.append(ele.strip())#從每個停止詞中，去除該死的換行符號\n",
    "    longTermsFreq=[]      #長詞+次數分配\n",
    "    for i in range(maxTermLength,1,-1): ##字詞數由大至小\n",
    "        text_list = cutSentence(path,stopwords)  \n",
    "        words_freq.update(ngram(text_list,i))\n",
    "        #for word_freq in words_freq:\n",
    "            #longTermsFreq.append(word_freq) #將長詞和次數加入另外一個list  分成兩個檔儲存的用意是減少迴圈次數\n",
    "    for key in words_freq:\n",
    "        if words_freq[key] >= minFreq:\n",
    "            brokenwords.update({key:words_freq[key]})\n",
    "    return words_freq\n",
    "\n",
    "#make a connection to mongodb \n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "db = client.test\n",
    "jurybook = db['jurybook']\n",
    "#print the case number in db.dday\n",
    "for dic in db.jurybook.find():\n",
    "    #print _uniout.unescape(str(i),'utf-8') \n",
    "    content = dic['content'] #append all the jurybook to the content\n",
    "    pk = dic['_id']\n",
    "    try:\n",
    "        longTermFreq = longTermPriority(content,5,1) ##最長詞5個字、出現頻次2次以上\n",
    "        longTermFreq.update({'_id':pk})\n",
    "    except:\n",
    "        f= codecs.open('./ngram/ngramerr.txt','w+' ,'utf-8')\n",
    "        f.write(pk)\n",
    "        pass\n",
    "    try:\n",
    "        jurybook_ngram = db['jurybook_ngram']\n",
    "        addmongo = db.jurybook_ngram.insert(longTermFreq)\n",
    "    except:\n",
    "        f= codecs.open('./ngram/inserterr.txt','w+' ,'utf-8')\n",
    "        f.write(pk)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('localhost',27017)\n",
    "#assign db_name to db\n",
    "db2 = client.test\n",
    "#print longTermFreq\n",
    "#for i in longTermFreq:\n",
    " #   print i[0],i[1]   #印出斷字結果\n",
    "#make a connection to mongodb \n",
    "import re\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "#make a connection to mongodb \n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "#assign db_name to db\n",
    "db2 = client.test\n",
    "#make the collection in the db of test\n",
    "brokenwords = db2['brokenwords']\n",
    "#print the case number in db.dday\n",
    "\n",
    "longTermFreq.update({'_id':pk})\n",
    "\n",
    "addbroken = db2.brokenwords.insert(longTermFreq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import _uniout\n",
    "import codecs,os\n",
    "try:\n",
    "    os.remove('ngramwords.txt')\n",
    "except:\n",
    "    pass\n",
    "for key in longTermFreq:\n",
    "    tt = chr(longTermFreq[key]).decode('utf8')\n",
    "    #print type(tt)\n",
    "    f = codecs.open('ngramwords.txt','a+','utf-8')\n",
    "    llist = key+','+str(longTermFreq[key]).decode('utf8')+'\\n'   #印出斷字結果\n",
    "    #print type(llist)\n",
    "    f.write(llist)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge dict and add values for keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.MyDict'>\n",
      "<class '__main__.MyDict'>\n",
      "{'a': 11, 'b': 5}\n"
     ]
    }
   ],
   "source": [
    "class MyDict(dict):\n",
    "    def __add__(self, oth):\n",
    "        #r = self.copy()\n",
    "        r =selft\n",
    "        try:\n",
    "            for key, val in oth.items():\n",
    "                if key in r:\n",
    "                    r[key] += val # You can custom it here\n",
    "                else:\n",
    "                    r[key] = val\n",
    "        except AttributeError: # In case oth isn't a dict\n",
    "            return NotImplemented # The convention when a case isn't handled\n",
    "\n",
    "        return r\n",
    "\n",
    "c = {'a':4,'b':5}\n",
    "d = {'a':7}\n",
    "\n",
    "a = MyDict(c)\n",
    "b = MyDict(dicnew2)\n",
    "\n",
    "print type(MyDict(dicnew2))\n",
    "print type(addic)\n",
    "print a+b\n",
    "#for i in addic:addic\n",
    " #   print i,addic[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
