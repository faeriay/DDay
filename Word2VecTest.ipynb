{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input the right format from mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from gensim.models import word2vec\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "db = client.sinicut_sw\n",
    "corpus = []\n",
    "for dic in db.plaintiff_sinica_sw.find({},{'_id':0}):\n",
    "    article = []\n",
    "    for ele in dic:\n",
    "        article.append(ele)\n",
    "    corpus.append(article)\n",
    "model = word2vec.Word2Vec(corpus,min_count=10 , size = 100, workers=4) #, window=10,, sample=1e-5\n",
    "model.save('sinicut_all_size100')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# input model formation by location and annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from gensim.models import word2vec\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "db = client.test\n",
    "corpus = []\n",
    "localzip =[100,111,220,260,200,320,300,350,400,500,540,700,800,970,630,602,950,900,880,890,209,850]\n",
    "for location in localzip:\n",
    "    #mergedic =MyDict(dicc)\n",
    "    for dic in db.plaintiff_sinica_sw.find({'_id':{'$regex':'^%d_'%(location)}},{'_id':0},no_cursor_timeout=True):\n",
    "        article = []\n",
    "        for ele in dic:\n",
    "            if ele != '_id':\n",
    "                article.append(ele)\n",
    "        corpus.append(article)\n",
    "    model = word2vec.Word2Vec(corpus,min_count=20 , size = 200, workers=4)\n",
    "    model.save('sinicut_location_%d'%(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from gensim.models import word2vec\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "db = client.test\n",
    "corpus = []\n",
    "annual = [89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104]\n",
    "\n",
    "for ayear in annual:\n",
    "    #mergedic =MyDict(dicc)\n",
    "    for dic in db.plaintiff_sinica_sw.find({'_id':{'$regex':'%d(\\d{4})$'%(ayear)}},{'_id':0},no_cursor_timeout=True):\n",
    "        article = []\n",
    "        for ele in dic:\n",
    "            if ele != '_id':\n",
    "                article.append(ele)\n",
    "        corpus.append(article)\n",
    "    model = word2vec.Word2Vec(corpus,min_count=20 , size = 200, workers=4)\n",
    "    model.save('sinicut_annual_%d'%(ayear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(corpus,min_count=20 , size = 200, workers=4)\n",
    "#model.train(corpus)\n",
    "model.save('sinicut_all_size800')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238\n"
     ]
    }
   ],
   "source": [
    "import glob,codecs\n",
    "\n",
    "worddic = {}\n",
    "for path in glob.glob('./cutTerms/sinicutonce_location2/*txt'):\n",
    "    f = codecs.open(path,'r','utf-8')\n",
    "    txtlist = f.readlines()\n",
    "    for txt in txtlist:\n",
    "        word = txt.split(',')[0]\n",
    "        if word not in worddic:\n",
    "            worddic[word]=1\n",
    "        else:\n",
    "            worddic[word]+=1\n",
    "print len(worddic)\n",
    "#for ele in worddic:\n",
    "#    print ele,worddic[ele]\n",
    "# 獨缺「居留証」\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs,glob\n",
    "\n",
    "worddic = {}\n",
    "for filetxt in glob.glob('./cutTerms/tfidf/*txt'):\n",
    "    f = codecs.open(filetxt,'r','utf-8')\n",
    "    wlist = f.readlines()\n",
    "    for word in wlist:\n",
    "        term = word.split(',')[1].strip()\n",
    "        if term not in worddic:\n",
    "            worddic[term]=1\n",
    "        else:\n",
    "            worddic[term]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import codecs\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "model = gensim.models.Word2Vec.load('word2vec/sinicut_all_size100')\n",
    "#model = gensim.models.Word2Vec('sinicut_once2')\n",
    "f = codecs.open('./cutTerms/word2vec_output2.txt','a+','utf-8')\n",
    "for word in worddic:\n",
    "    count =1\n",
    "    try:\n",
    "        for w in model.most_similar(word):\n",
    "            intxt = word+';'+str(count).decode('utf-8')+','+w[0]+';'+'\\n'\n",
    "            count+=1\n",
    "            f.write(intxt)\n",
    "    except:\n",
    "        print word\n",
    "        pass\n",
    "f.close()\n",
    "\n",
    "#calculate similarity\n",
    "#for w in model.most_similar('kimono'):\n",
    "#    print w[0].encode('utf-8'), w[1]\n",
    "#sm = model.most_similar([u'毆打'])\n",
    "#for ele in sm:\n",
    "#    print ele[0].encode('utf-8'),ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 檢驗兩個共同出現的案件數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "db = client.sinicut_sw\n",
    "check = False\n",
    "check2 = False\n",
    "count = 0\n",
    "for dic in db.plaintiff_sinica_sw.find({},{'_id':0}):\n",
    "    for ele in dic:\n",
    "        if ele == u'外遇':\n",
    "            check = True\n",
    "        if ele == u'婚外情':\n",
    "            check2 = True\n",
    "    if check & check2:\n",
    "        count+=1\n",
    "    check = False\n",
    "    check2 = False\n",
    "print count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
